{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "title: Running a Phylogenetic OU Regression with R and Stan\n",
        "jupyter: ir\n",
        "---\n",
        "\n",
        "\n",
        "In this notebook, I will illustrate how one can set up a logistic regression with a phylogenetic random effect following an Ornstein-Uhlenbeck process using R and Stan. \n",
        "\n",
        "This kind of analysis has conceptual advantages compared with alternatives - such as phylogenetic random effects following a Brownian motion, or correlated evolution using discrete characters and the CTMC model. However, while there are off-the-shelf solutions for the latter two, the OU regression is, to my knowledge, not yet implemented in a dedicated function or package. Such a model can be set up quite easily in Stan, however. This notebook serves to illustrate how this can be done.\n",
        "\n",
        "\n",
        "## Preparing the environment\n",
        "\n",
        "The git repository contains a file `OU_logistic_example.yml`. You can use it to set up a conda environment containing all the required packages. (Of course you can also install the packages with `install.packages` if you don't use conda.) At the command prompt, in the home directory of the repository, do\n",
        "\n",
        "```{bash}\n",
        "conda env create -f OU_logistic_example.yml\n",
        "conda activate OU_logistic_example\n",
        "```\n",
        "\n",
        "## Loading the required packages\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "library(tidyverse)\n",
        "library(rstan)\n",
        "library(parallel)\n",
        "rstan_options(auto_write = TRUE)\n",
        "options(mc.cores = parallel::detectCores())  # Enable parallel Stan sampling\n",
        "library(ape)\n",
        "library(R.utils)\n",
        "library(bridgesampling)\n",
        "library(loo)\n",
        "library(bayesplot)\n",
        "library(codetools)\n",
        "library(ggtree)\n",
        "library(posterior)\n",
        "library(tidybayes)\n",
        "library(ggthemes)\n",
        "library(paletteer)\n",
        "library(ggnewscale)\n",
        "options(repr.plot.width = 12, repr.plot.height = 8)  # For base R plots in Jupyter\n",
        "theme_set(theme_minimal(base_size = 24))  # Increase base font size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data\n",
        "\n",
        "Now let's get some data. I will use the EDGE tree (Bouckaert 2022)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Create data directory if it doesn't exist\n",
        "if (!dir.exists(\"../data\")) dir.create(\"../data\", recursive = TRUE)\n",
        "\n",
        "# Download the file if it doesn't exist\n",
        "tree_gz <- \"../data/global-language-tree-MCC-labelled.tree.gz\"\n",
        "tree_file <- \"../data/global-language-tree-MCC-labelled.tree\"\n",
        "if (!file.exists(tree_file)) {\n",
        "    download.file(\n",
        "        url = \"https://github.com/rbouckaert/global-language-tree-pipeline/releases/download/v1.0.0/global-language-tree-MCC-labelled.tree.gz\",\n",
        "        destfile = tree_gz,\n",
        "        mode = \"wb\"\n",
        "    )\n",
        "    R.utils::gunzip(tree_gz, destname = tree_file, overwrite = TRUE)\n",
        "    # Remove the gzipped file after extraction\n",
        "    if (file.exists(tree_gz)) file.remove(tree_gz)\n",
        "}\n",
        "\n",
        "edge_tree <- read.nexus(tree_file)\n",
        "\n",
        "edge_tree$tip.label <- sapply(strsplit(edge_tree$tip.label, \"_\"), `[`, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is advisable to rescale the tree so that the median branch length is 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "edge_tree$edge.length <- edge_tree$edge.length / (median(edge_tree$edge.length))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Grambank data\n",
        "\n",
        "I will look at the somewhat boring feature pair:\n",
        "- GB193: What is the order of adnominal property word and noun?\n",
        "- GB133: Is a pragmatically unmarked constituent order verb-final for transitive clauses?\n",
        "\n",
        "\n",
        "\n",
        "First we get the grambank data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "grambank_file = \"../data/grambank_vals.csv\"\n",
        "if (!file.exists(grambank_file)) {\n",
        "    values_url <- \"https://raw.githubusercontent.com/grambank/grambank/refs/heads/master/cldf/values.csv\"\n",
        "    vals <- read_csv(values_url, na = \"\")\n",
        "    write(vals, grambank_file)\n",
        "} else {\n",
        "    vals <- read_csv(grambank_file)\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we filter out the datapoints for the two parameters of interest and the languages in the tree. I only consider two values per parameter, and only languages having a relevant value for both parameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "d <- vals %>%\n",
        "    filter(Language_ID %in% edge_tree$tip.label) %>%\n",
        "    filter(Parameter_ID %in% c(\"GB193\", \"GB133\")) %>%\n",
        "    select(Language_ID, Parameter_ID, Value) %>%\n",
        "    filter(Value %in% c(0, 1, 2)) %>%\n",
        "    mutate(Value = as.numeric(Value)) %>%\n",
        "    pivot_wider(names_from = Parameter_ID, values_from = Value) %>%\n",
        "    filter(GB193 > 0) %>%\n",
        "    drop_na()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we prune the tree to only include the languages in the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pruned_tree <- drop.tip(edge_tree, setdiff(edge_tree$tip.label, d$Language_ID))\n",
        "\n",
        "# Check that d$Language_ID and pruned_tree$tip.label are the same set\n",
        "if (!setequal(d$Language_ID, pruned_tree$tip.label)) {\n",
        "    warning(\"Mismatch between d$Language_ID and pruned_tree$tip.label\")\n",
        "    print(setdiff(d$Language_ID, pruned_tree$tip.label))\n",
        "    print(setdiff(pruned_tree$tip.label, d$Language_ID))\n",
        "} else {\n",
        "    message(\"d$Language_ID and pruned_tree$tip.label match.\")\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now the rows in `d` are rearranged to match the order of the tips in the pruned tree."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "d <- d[match(pruned_tree$tip.label, d$Language_ID), ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Finally we convert the features to numeric values, and convert to 0/1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "d <- d %>%\n",
        "    mutate(x = GB193 - 1,\n",
        "           y = GB133 \n",
        "    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's have a look at the tree and the data.\n",
        "\n",
        "For now, I keep the data set small and restrict myself to 100 taxa."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "set.seed(123)  # You can replace 123 with any integer\n",
        "d <- d[sample(nrow(d), 100), ]\n",
        "pruned_tree <- drop.tip(pruned_tree, setdiff(pruned_tree$tip.label, d$Language_ID))\n",
        "d <- d[match(pruned_tree$tip.label, d$Language_ID), ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ggtree(pruned_tree, layout=\"circular\") +\n",
        "    geom_tree() +\n",
        "    geom_tiplab() +            # Adds tip labels\n",
        "    theme_tree2()              # Adds scale axis (x-axis for branch lengths)\n",
        "\n",
        "\n",
        "d %>% head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Stan model\n",
        "\n",
        "The tree is represented as a phylo object in `ape`, which is suitable for Stan.\n",
        "\n",
        "Just to be on the safe side, we make sure that the branches are in postorder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pruned_tree <- reorder(pruned_tree, \"postorder\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we code the tree and the data as a data list."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "stan_data = list(\n",
        "    N = nrow(d),  # Number of languages\n",
        "    Nnodes = length(unique(as.vector(pruned_tree$edge))),\n",
        "    root_node = length(pruned_tree$tip.label) + 1,\n",
        "    x = d$x,  # Predictor variable (numeral-noun order)\n",
        "    y = d$y,  # Response variable (adnominal demonstrative-noun order)\n",
        "    Nedges = nrow(pruned_tree$edge), # number of edges\n",
        "    edges = pruned_tree$edge,  # Edges of the tree,\n",
        "    edge_lengths = pruned_tree$edge.length  # Lengths of the edges\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false
      },
      "source": [
        "stan_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Vanilla logistic regression\n",
        "\n",
        "We start with a simple logistic regression without any phylogenetic effects, just to see how it works.\n",
        "\n",
        "The model formula is:\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\alpha &\\sim \\mathcal N(0, 10)\\\\\n",
        "\\beta &\\sim \\mathcal N(0, 10)\\\\\n",
        "y &\\sim \\text{Bernoulli}(\\text{logit}^{-1}(\\alpha + \\beta x))\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Let's run this in Stan."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "stan_code_vanilla <- \"\n",
        "data {\n",
        "    int<lower=1> N;                      // Number of observations\n",
        "    vector<lower=0, upper=1>[N] x;                         // Predictor variable\n",
        "    array[N] int<lower=0,upper=1> y;     // Response variable (binary)\n",
        "}\n",
        "parameters {\n",
        "    real alpha;      // Intercept\n",
        "    real beta;       // Slope\n",
        "}\n",
        "model {\n",
        "    // Priors\n",
        "    alpha ~ normal(0, 10);\n",
        "    beta ~ normal(0, 10);\n",
        "\n",
        "    // Likelihood\n",
        "    y ~ bernoulli_logit(alpha + beta * x);\n",
        "}\n",
        "generated quantities {\n",
        "    vector[N] log_lik;\n",
        "    for (n in 1:N) {\n",
        "        log_lik[n] = bernoulli_logit_lpmf(y[n] | alpha + beta * x[n]);\n",
        "    }\n",
        "}\n",
        "\"\n",
        "stan_model_vanilla <- stan_model(model_code = stan_code_vanilla)\n",
        "fit_vanilla <- sampling(stan_model_vanilla, data = stan_data, iter = 2000, chains = 4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(fit_vanilla, pars = c(\"alpha\", \"beta\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mcmc_areas(\n",
        "    as.matrix(fit_vanilla),\n",
        "    pars=\"beta\",\n",
        "    prob = 0.95\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The posterior distribution of the slope $\\beta$ does not include zero, indicating that there is a significant relationship between the predictor variable `x` and the response variable `y`. The direction is negative, meaning that N-ANM order disfavors OV order.\n",
        "\n",
        "\n",
        "For model comparison, we can use the `bridgesampling` package to compute the log marginal likelihood."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "log_marginal_likelihood_vanilla_regression <- bridge_sampler(fit_vanilla)\n",
        "print(log_marginal_likelihood_vanilla_regression)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Vanilla logistic correlation study\n",
        "\n",
        "A regression model assumes an asymmetry between the predictor variable (which is not modeled) and the response variabel (which is modeled). This is not really justified in observational studies where we have not control over the predictor variable. A more appropriate model is one where both variables are generated by some stochastic process. \n",
        "\n",
        "This can be modeled as follows:\n",
        "\n",
        "$$\t\n",
        "\\begin{align}\n",
        "z &\\sim \\mathcal N(\\mu, R)\\\\\n",
        "R &\\sim \\text{LKJ}(2)\\\\\n",
        "\\mu &= \\mathcal N(\\mathbf 0, 5\\mathbf I)\\\\\n",
        "x &\\sim \\text{Bernoulli}(\\text{logit}^{-1}(z_1))\\\\\n",
        "y &\\sim \\text{Bernoulli}(\\text{logit}^{-1}(z_2))\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "Here $z$ is a bivariate normal variable with mean $\\mu$ and covariance $R$. The two components of $z$ have standard deviations 1, and the correlation between them is given by $\\rho = R_{12} = R_{21}$. The correlation matrix is generated from a uniform distribution distribution, which is a flexible way to model correlations. The two variables $x$ and $y$ are then generated from the first and second components of $z$, respectively, using the logistic function. \n",
        "\n",
        "The interesting question is then whether the correlation between $x$ and $y$, i.e., $\\rho = r_{21}$, is significantly different from zero. If it is, this indicates that there is a significant correlation between the two variables, which is what we are interested in."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "stan_code_vanilla_corr <- \"\n",
        "data {\n",
        "  int<lower=0> N;\n",
        "  array[N] int<lower=0, upper=1> x;\n",
        "  array[N] int<lower=0, upper=1> y;\n",
        "}\n",
        "\n",
        "parameters {\n",
        "  vector[2] mu;                          // Mean of latent variables\n",
        "  cholesky_factor_corr[2] L_R;           // Cholesky factor of correlation matrix\n",
        "  matrix[2, N] z_raw;                    // Standard normal latent variables\n",
        "}\n",
        "\n",
        "transformed parameters {\n",
        "  real rho = L_R[2, 1];\n",
        "  matrix[2, N] z;\n",
        "  z = rep_matrix(mu, N) + L_R * z_raw;\n",
        "}\n",
        "\n",
        "model {\n",
        "  // Priors\n",
        "  mu ~ normal(0, 5);\n",
        "  L_R ~ lkj_corr_cholesky(2);\n",
        "  to_vector(z_raw) ~ normal(0, 1); // standard normal prior for latent\n",
        "\n",
        "  // Likelihood\n",
        "  for (n in 1:N) {\n",
        "    x[n] ~ bernoulli_logit(z[1, n]);\n",
        "    y[n] ~ bernoulli_logit(z[2, n]);\n",
        "  }\n",
        "}\n",
        "\n",
        "generated quantities {\n",
        "  vector[N] log_lik_x;\n",
        "  vector[N] log_lik_y;\n",
        "\n",
        "  for (n in 1:N) {\n",
        "    log_lik_x[n] = bernoulli_logit_lpmf(x[n] | z[1, n]);\n",
        "    log_lik_y[n] = bernoulli_logit_lpmf(y[n] | z[2, n]);\n",
        "  }\n",
        "}\n",
        "\"\n",
        "stan_model_vanilla_corr <- stan_model(model_code = stan_code_vanilla_corr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit_vanilla_corr <- sampling(\n",
        "    stan_model_vanilla_corr,\n",
        "    data = stan_data,\n",
        "    iter = 2000,\n",
        "    chains = 4,\n",
        "    control = list(adapt_delta = 0.95, max_treedepth = 15)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(fit_vanilla_corr, pars = c(\"mu\", \"rho\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mcmc_areas(\n",
        "    as.matrix(fit_vanilla_corr),\n",
        "    pars = \"rho\",\n",
        "    prob = 0.95\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The posterior of $\\rho$ is clearly negative, with the HPD interval excluding 0. \n",
        "\n",
        "\n",
        "We compute the log marginal likelihood for this model for later use."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "log_marginal_likelihood_vanilla_corr <- bridge_sampler(fit_vanilla_corr)\n",
        "print(log_marginal_likelihood_vanilla_corr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A direct model comparison via Bayes Factor is not possible because the regression model models the distribution of `x` given `y`, while the correlation models the joint distribution. However, we can apply Pareto-smoothed leave one out cross-validation if we marginalize over `x` in the correlation model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# extract log-likelihood matrix: draws x observations\n",
        "log_lik1 <- extract_log_lik(fit_vanilla, parameter_name = \"log_lik\")\n",
        "log_lik2 <- extract_log_lik(fit_vanilla_corr, parameter_name = \"log_lik_y\")\n",
        "\n",
        "# compute LOO\n",
        "loo1 <- loo(log_lik1)\n",
        "loo2 <- loo(log_lik2)\n",
        "\n",
        "# compare\n",
        "loo_compare(loo1, loo2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "So the regression model is slightly preferred, but the difference is almost indistinguishable from zero.\n",
        "\n",
        "\n",
        "### The Ornstein-Uhlenbeck process\n",
        "\n",
        "\n",
        "The OU process is a stochastic process, similar to Brownian motion. The crucial difference is that OU is ``random walk on a leash``. Technically, it is the mixture of a stochastic Brownian motion process and a deterministic trajectory exponentially converging to a mean value. It is characterized by the following distribution:\n",
        "$$\n",
        "X_t \\sim \\mathcal N\\left(x_0e^{-\\lambda t} + \\mu (1-e^{-\\lambda t}), \\frac{\\sigma}{\\sqrt{2\\lambda}}\\sqrt{1-e^{-2\\lambda t}}\\right)\n",
        "$$\n",
        "\n",
        "The parameters are:\n",
        "\n",
        "- $x_0$: the initial value of the process\n",
        "- $\\mu$: the mean value to which the process converges\n",
        "- $\\lambda$: the rate of convergence to the mean value\n",
        "- $\\sigma$: the volatility of the process\n",
        "- $t$: the time at which the process is evaluated\n",
        "\n",
        "The long-term equilibrium distribution is:\n",
        "$$\n",
        "X_t \\sim \\mathcal N(\\mu, \\frac{\\sigma}{\\sqrt{2\\lambda}})\n",
        "$$\n",
        "\n",
        "\n",
        "\n",
        "## Logistic regression with a phylogenetic random effect\n",
        "\n",
        "We now add a phylogenetic random effect to the logistic regression from above:\n",
        "\n",
        "\n",
        "$$\n",
        "\\begin{align}\n",
        "\\alpha &\\sim \\mathcal N(0, 10)\\\\\n",
        "\\beta &\\sim \\mathcal N(0, 10)\\\\\n",
        "\\epsilon &\\sim \\mathcal N(0, \\Sigma)\\\\\n",
        "y &\\sim \\text{Bernoulli}(\\text{logit}^{-1}(\\alpha + \\beta x + \\epsilon))\n",
        "\\end{align}\n",
        "$$\n",
        "\n",
        "The covariance matrix $\\Sigma$ of the phylogenetic random effect is given by\n",
        "\n",
        "$$\n",
        "\\Sigma_{ij} = \\frac{\\sigma^2}{2\\lambda} e^{-\\lambda t_{ij}},\n",
        "$$\n",
        "\n",
        "where $t_{ij}$ is the patristic distance between language $i$ and language $j$ in the phylogeny.\n",
        "\n",
        "\n",
        "A direct implementation of this formula in Stan is possible but inefficient. A better approach directly simulates the evolution of the latent variable $\\epsilon$ along the phylgeny. This means that $\\epsilon$ has a value not only at the tips but also at the internal nodes. The value at the root is sampled from the equilibrium distribution, and the value of the other nodes is drawn from the equation above, repeated here:\n",
        "\n",
        "$$\n",
        "X_t \\sim \\mathcal N(x_0e^{-\\lambda t} + \\mu (1-e^{-\\lambda t}), \\frac{\\sigma^2}{2\\lambda}(1-e^{-2\\lambda t})).\n",
        "$$\n",
        "\n",
        "$X_t$ is now the value at the daughter node, $x_0$ at the mother node, and $t$ is the branch length."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "stan_model_OU_regression <- stan_model(file = \"OU_regression.stan\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false
      },
      "source": [
        "fit_OU_regression <- sampling(\n",
        "    stan_model_OU_regression,\n",
        "    data = stan_data,\n",
        "    iter = 2000,\n",
        "    chains = 4,\n",
        "    control = list(adapt_delta = 0.95, max_treedepth = 15)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(fit_OU_regression, pars = c(\"mu\", \"sigma\", \"lambda\", \"alpha\", \"beta\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mcmc_areas(\n",
        "    as.matrix(fit_OU_regression),\n",
        "    pars = \"beta\",\n",
        "    prob = 0.95\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "log_marginal_likelihood_OU_regression <- bridge_sampler(fit_OU_regression)\n",
        "print(log_marginal_likelihood_OU_regression)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can compute the Bayes factor between the vanilla regression and the OU phylogenetic regression."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "log_marginal_likelihood_OU_regression$logml - log_marginal_likelihood_vanilla_regression$logml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This is extremely strong evidence in favor of the OU model.\n",
        "\n",
        "The HPD for $\\beta$ is very broad and includes 0. So there is no evidence for the significant effect of the order of adnominal property words on verb position.\n",
        "\n",
        "However, I find it hard to wrap my mind around what such a model actually means. It says that there is a latent variable $\\epsilon$ evolving along the tree, and the probability of a language being verb final depends both on this latent variable and on the order of adjective-noun.\n",
        "\n",
        "A more realistic model, it seems to me, is one where there are\n",
        "\n",
        "- a latent variable determining adjective-noun order, and\n",
        "- a latent variable determining verb position.\n",
        "\n",
        "These latent variables evolve simultaneously along the tree. If there is a dependency between the two observed variables resulting from diachronic processes, there is a correlation between the diachronic changes of the variables.\n",
        "\n",
        "This can be implemented in an extension of the bivariate correlation model used above.\n",
        "\n",
        "The model specification is as follows, where $N$ is the number of languages, and $t_{l_1, l_2}$ is the length of from the root of the tree to the most recent common ancestor of $l_1$ and $l_2$:\n",
        "\n",
        "$$\t\n",
        "\\begin{align}\n",
        "R &\\sim \\text{LKJ}(2)\\\\\n",
        "\\Sigma_{(l_1, k_1), (l_2, k_2)} &= R_{k_1, k_2}\\cdot \\frac{\\sigma_{k_1}\\sigma_{k_2}}{\\lambda_{k_1}+\\lambda_{k_2}}\\left(1-e^{-(\\lambda_{k_1}+\\lambda_{k_2})t_{l_1, l_2}}\\right)\n",
        "\\\\\n",
        "\\mu_i &= \\mathcal N(\\mathbf 0, 2)\\\\\n",
        "\\sigma_i &= \\text{Lognormal}(0,1)\\\\\n",
        "\\lambda_i &= \\text{Lognormal}(0,1)\\\\\n",
        "z &\\sim \\mathcal N(\\text{repeat}(\\mu, N), \\Sigma)\\\\\n",
        "x_i &\\sim \\text{Bernoulli}(\\text{logit}^{-1}(z_{i,1}))\\\\\n",
        "y_i &\\sim \\text{Bernoulli}(\\text{logit}^{-1}(z_{i,2}))\n",
        "\\end{align}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "stan_model_OU_correlation <- stan_model(file = \"OU_correlation.stan\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit_OU_correlation <- sampling(\n",
        "    stan_model_OU_correlation,\n",
        "    data = stan_data,\n",
        "    iter = 10000,\n",
        "    thin = 10,\n",
        "    chains = 4,\n",
        "    control = list(adapt_delta = 0.95, max_treedepth = 15)\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(fit_OU_correlation, pars=c(\"mu\", \"sigma\", \"lambda\", \"rho\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "mcmc_areas(\n",
        "    as.matrix(fit_OU_correlation),\n",
        "    pars = \"rho\",\n",
        "    prob = 0.95\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since the HPD of $\\rho$ includes 0, we conclude that there is no credible evidence for a diachronic correlation between the two variables.\n",
        "\n",
        "Bayes factor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "log_marginal_likelihood_OU_correlation <- bridge_sampler(fit_OU_correlation)\n",
        "print(log_marginal_likelihood_OU_correlation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "log_marginal_likelihood_OU_correlation$logml - log_marginal_likelihood_vanilla_corr$logml"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Again we find overwhelming evidence in favor of the phylogenetic model.\n",
        "\n",
        "We can complement model comparison via Bayes Factor with Pareto-smoothed leave-one-out cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true
      },
      "source": [
        "# extract log-likelihood matrix: draws x observations\n",
        "log_lik1 <- extract_log_lik(fit_vanilla, parameter_name = \"log_lik\")\n",
        "log_lik2 <- extract_log_lik(fit_vanilla_corr, parameter_name = \"log_lik_y\")\n",
        "log_lik3 <- extract_log_lik(fit_OU_regression, parameter_name = \"log_lik\")\n",
        "log_lik4 <- extract_log_lik(fit_OU_correlation, parameter_name = \"log_lik_y\")\n",
        "\n",
        "\n",
        "# compute LOO\n",
        "loo1 <- loo(log_lik1)\n",
        "loo2 <- loo(log_lik2)\n",
        "loo3 <- loo(log_lik3)\n",
        "loo4 <- loo(log_lik4)\n",
        "\n",
        "# compare\n",
        "loo_compare(loo1, loo2, loo3, loo4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The two phylogenetic models perform massively better than the vanilla models. Furthermore if our goal is to predict the verb position of an unseen language from its noun-adjective order and its position in the tree, the regression model is superior to the correlation model.\n",
        "\n",
        "As a nice side effect of the explicit modeling of the diachronic histories, we can plot the posterior means of the latent variables at the internal nodes, thereby visualizing the evolution of the latent variables. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "posterior_df <- as_draws_df(fit_OU_correlation)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "z_posterior <- posterior_df %>%\n",
        "  spread_draws(z[i, j]) %>%\n",
        "  group_by(i, j) %>%\n",
        "  summarise(mean_z = mean(z), .groups = \"drop\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "z_adjective <- z_posterior %>%\n",
        "    filter(j == 1) %>%\n",
        "    pull(mean_z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "z_vo <- z_posterior %>%\n",
        "    filter(j == 2) %>%\n",
        "    pull(mean_z)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "pruned_tree$node.label <- as.character(\n",
        "    (length(pruned_tree$tip.label) + 1):(length(pruned_tree$tip.label) + pruned_tree$Nnode)\n",
        ")\n",
        "\n",
        "\n",
        "tree_plot <- ggtree(pruned_tree)\n",
        "tree_info <- tree_plot$data\n",
        "tree_info$node.label <- as.character(tree_info$label)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "for (i in 1:nrow(tree_info)) {\n",
        "    if (tree_info$isTip[i]) {\n",
        "        # If it's a tip, get the corresponding Glottocode\n",
        "        glottocode <- tree_info$label[i]\n",
        "        # Find the index of the Glottocode in d_ie\n",
        "        index <- which(pruned_tree$tip.label == glottocode)\n",
        "        # Assign the Affix value to the node label\n",
        "        tree_info$node.label[i] <- index\n",
        "    } else {\n",
        "        # If it's not a tip, copy label\n",
        "        tree_info$node.label[i] <- as.integer(tree_info$node.label[i])\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "node_data <- tibble(\n",
        "  node.label = as.character(1:length(z_adjective)),\n",
        "  z_adjective = z_adjective,\n",
        "  z_vo = z_vo\n",
        ")\n",
        "\n",
        "\n",
        "tree_data <- tree_info %>%\n",
        "  left_join(node_data, by = \"node.label\")\n",
        "\n",
        "tree_data <- tree_data %>%\n",
        "    left_join(\n",
        "        rename(select(d, Language_ID, GB193, GB133),\n",
        "        label=Language_ID)\n",
        "    ) \n",
        "tree_data <- tree_data %>%\n",
        "  mutate(GB193 = factor(GB193)) %>%\n",
        "  mutate(GB133 = factor(GB133))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "custom_palette <- paletteer_c(\"ggthemes::Classic Orange-Blue\", 30)\n",
        "\n",
        "# Plot with two color scales\n",
        "ggtree(pruned_tree, layout=\"circular\") %<+% tree_data +\n",
        "  # First color scale for branches\n",
        "  geom_tree(aes(color = z_adjective)) +\n",
        "  scale_color_gradientn(colors = custom_palette) +\n",
        "\n",
        "  # Reset color scale\n",
        "  ggnewscale::new_scale_color() +\n",
        "\n",
        "  # Color tip points by a discrete or continuous variable\n",
        "  geom_tippoint(aes(color = GB193), size = 2) +\n",
        "  scale_color_manual(values = c(\"1\" = \"red\", \"2\" = \"blue\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "ggtree(pruned_tree, layout = \"circular\") %<+% tree_data +\n",
        "  # First color scale for branches\n",
        "  geom_tree(aes(color = z_vo)) +\n",
        "  scale_color_gradientn(colors = custom_palette) +\n",
        "\n",
        "  # Reset color scale\n",
        "  ggnewscale::new_scale_color() +\n",
        "\n",
        "  # Color tip points by a discrete or continuous variable\n",
        "  geom_tippoint(aes(color = GB133), size = 2) +\n",
        "  scale_color_manual(values = c(\"0\" = \"red\", \"1\" = \"blue\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Another advantage of this approach (both the regression and the correlation variant) is that it can easily be combined with family-level or macroarea-level random effects. Also, geographic random effects can easily be added.\n",
        "\n",
        "More details can be found in my arxiv paper *Computational Tyology* (https://arxiv.org/abs/2504.15642)\n",
        "\n",
        "## Pagel & Meade style test for correlation\n",
        "\n",
        "The test for correlation using CTMC, as developed by Pagel & Meade (2006) and implemented in BayesTraits, can also be implemented in Stan, using Felsenstein's pruning algorithm.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "stan_model_ctmc_independent <- stan_model(file = \"ctmc_independent.stan\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit_ctmc_independent <- sampling(\n",
        "    stan_model_ctmc_independent,\n",
        "    data = stan_data,\n",
        "    iter = 2000,\n",
        "    chains = 4\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(fit_ctmc_independent, pars=c(\"pi_1\", \"pi_2\", \"rates\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "log_marginal_likelihood_ctmc_independent <- bridge_sampler(fit_ctmc_independent)\n",
        "print(log_marginal_likelihood_ctmc_independent)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "stan_model_ctmc_dependent <- stan_model(file = \"ctmc_dependent.stan\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "fit_ctmc_dependent <- sampling(\n",
        "    stan_model_ctmc_dependent,\n",
        "    data = stan_data,\n",
        "    iter = 2000,\n",
        "    chains = 4\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "print(fit_ctmc_dependent, pars=c(\"total_rate\", \"rates\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "log_marginal_likelihood_ctmc_dependent <- bridge_sampler(fit_ctmc_dependent)\n",
        "print(log_marginal_likelihood_ctmc_dependent)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "ir",
      "language": "R",
      "display_name": "R",
      "path": "/usr/share/jupyter/kernels/ir"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}